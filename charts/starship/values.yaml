# Default values for tricorder.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: "starship"

tolerations: []

affinity: {}

podAnnotations: {}

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

replicaCount: 1
service:
  type: ClusterIP
  port: 80

apiServer:
  service:
    type: LoadBalancer

  image:
    repository: public.ecr.aws/tricorder/api-server
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: ""

  persistentVolumes:
    data:
      enabled: true
      ## database data Persistent Volume Storage Class
      ## If defined, storageClassName: <storageClass>
      ## If set to "-", storageClassName: "", which disables dynamic provisioning
      ## If undefined (the default) or set to null, no storageClassName spec is
      ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
      ##   GKE, AWS & OpenStack)
      storageClass:
      size: 200Mi
      subPath: "tricorder.db"
      mountPath: "/tricorder/"
      accessModes:
        - ReadWriteOnce
  command:
    extraArgs:
      - --module_db_dir_path=/tricorder/
      # PG username and password setting is on the below 'timescale.database.username' && 'timescale.database.password'
      # Database name setting is in templates/tricorder-data-int/post-init-configmap.yaml
      - --pg_url=postgresql://postgres:tricorder@timescaledb:5432/tricorder

  ports:
    serverhttp:
      enabled: true
      containerPort: 8080
      servicePort: 8080
      protocol: TCP
    grpc:
      enabled: true
      containerPort: 50051
      servicePort: 50051
      protocol: TCP

  resources:
    limits:
      cpu: 400m
      memory: 500Mi
    requests:
      cpu: 100m
      memory: 128Mi

agent:
  image:
    repository: public.ecr.aws/tricorder/agent
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: ""

ui:
  image:
    repository: public.ecr.aws/tricorder/mgmt-ui
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: ""

  ports:
    uihttp:
      enabled: true
      containerPort: 80
      servicePort: 80
      protocol: TCP
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi

timescaledb-single:
  enabled: true
  # This file and its contents are licensed under the Apache License 2.0.
  # Please see the included NOTICE for copyright information and LICENSE for a copy of the license.

  replicaCount: 1

  # To prevent very long names, we override the name, otherwise it would default to
  # timescaledb-single (the name of the chart)
  fullnameOverride: timescaledb
  #clusterName: "{{ .Release.Name }}-tsdb"

  image:
    # Image was built from
    # https://github.com/timescale/timescaledb-docker-ha
    repository: timescale/timescaledb-ha
    # TODO(jian): bump helm chart, https://github.com/timescale/helm-charts/issues/405#issuecomment-1340996682
    tag: pg14.6-ts2.8.1-patroni-static-primary-p3
  # By default those secrets are randomly generated.
  # To prevent misconfiguration, modifications from helm upgrade won't be applied to those secrets.
  # As a result changing secrets cannot be done via helm and need manual intervention.
  secrets:
    # This map should contain environment variables that influence Patroni,
    # for example PATRONI_SUPERUSER_PASSWORD or PATRONI_REPLICATION_PASSWORD
    # https://patroni.readthedocs.io/en/latest/ENVIRONMENT.html#postgresql
    credentials:
      PATRONI_SUPERUSER_PASSWORD: "tricorder"
      PATRONI_REPLICATION_PASSWORD: "tricorder"
      PATRONI_admin_PASSWORD: "tricorder"

    # This secret should contain environment variables that influence pgBackRest.
    pgbackrest:
      PGBACKREST_REPO1_S3_REGION: ""
      PGBACKREST_REPO1_S3_KEY: ""
      PGBACKREST_REPO1_S3_KEY_SECRET: ""
      PGBACKREST_REPO1_S3_BUCKET: ""
      PGBACKREST_REPO1_S3_ENDPOINT: "s3.amazonaws.com"

    # Selector used to provision your own Secret containing pgbackrest configuration details
    # This is mutually exclusive with `pgbackrest` option and takes precedence over it.
    # WARNING: Use this option with caution
    pgbackrestSecretName: ""

  backup:
    enabled: false

  # Extra custom environment variables.
  # These should be an EnvVar, as this allows you to inject secrets into the environment
  # https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.16/#envvar-v1-core
  env:
    - name: TSTUNE_PROFILE
      value: promscale

  # Externally created Kubernetes secrets will be injected into the pods by referencing them here. You
  # can also add more configuration options and secrets this way (see https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-container-environment-variables)
  envFrom:
  #  - configMapRef:
  #      name: my-deployment-settings
  #      optional: true


  # This configuration will be passed on to Patroni directly, there are a few things that are
  # injected/changed, these are:
  #   - archive_command will be set to /bin/true if backup is disabled
  #   - any context sensitive parameter (scope, namespace, name) will be overridden by the Kubernetes context
  # https://patroni.readthedocs.io/en/latest/SETTINGS.html#settings
  # refs: https://docs.timescale.com/promscale/latest/recommendations/config-recomm/#database-configuration
  patroni:
    bootstrap:
      dcs:
        postgresql:
          parameters:
            max_connections: 500
            checkpoint_timeout: 15min
            bgwriter_delay: 10ms
            bgwriter_lru_maxpages: 100000
            synchronous_commit: "off"
            shared_preload_libraries: timescaledb,pg_stat_statements,pg_stat_monitor,pg_stat_kcache
            # TODO: stats_temp_directory was deprectated on PG15, we should remove it when the DB upgrades.
            stats_temp_directory: /tmp/pg_stat_temp

  postInit:
    # Post innitialization script for timescaledb, see its definition in
    # templates/tricorder-database-init/post-init-configmap.yaml
    # Post initialization setup details:
    # https://github.com/timescale/helm-charts/blob/main/charts/timescaledb-single/docs/admin-guide.md#post-init-scripts
    # A list of sources, that contain post init scripts.
    # These scripts are all projected to the same directory and will be executed
    # in sorted order only once: After a cluster initialization
    # Some examples:
    - configMap:
        name: timescale-post-init
  # Values for defining the primary & replica Kubernetes Services.
  service:
    primary:
      # One of (ClusterIP | LoadBalancer | NodePort). Headless services are not supported.
      type: ClusterIP
      # The port used by the service.
      port: 5432
      # Additional labels to be added to the Service.
      labels: {}
      # Additional annotations to be added to the Service.
      annotations: {}
      # Define extra fields to be interpolated into the Service spec.
      #
      # This allows for adding support for new features and functionality which may not yet
      # be directly supported in this chart.
      spec: {}
      # loadBalancerSourceRanges:
      # - "0.0.0.0/0"

    replica:
      # One of (ClusterIP | LoadBalancer | NodePort). Headless services are not supported.
      type: ClusterIP
      # The port used by the service.
      port: 5432
      # Additional labels to be added to the Service.
      labels: {}
      # Additional annotations to be added to the Service.
      annotations: {}
      # Define extra fields to be interpolated into the Service spec.
      #
      # This allows for adding support for new features and functionality which may not yet
      # be directly supported in this chart.
      spec: {}
      # loadBalancerSourceRanges:
      # - "0.0.0.0/0"

  persistentVolumes:
    # For sanity reasons, the actual PGDATA and wal directory will be subdirectories of the Volume mounts,
    # this allows Patroni/a human/an automated operator to move directories during bootstrap, which cannot
    # be done if we did not use subdirectories
    # https://www.postgresql.org/docs/current/creating-cluster.html#CREATING-CLUSTER-MOUNT-POINTS
    data:
      size: 150Gi
    wal:
      size: 20Gi

  resources:
    requests:
      cpu: 100m
      memory: 2Gi
  sharedMemory:
    useMount: true

  # timescaledb-tune will be run with the Pod resources requests or - if not set - its limits.
  # This should give a reasonably tuned PostgreSQL instance.
  # Any PostgreSQL parameter that is explicitly set in the Patroni configuration will override
  # the auto-tuned variables.
  timescaledbTune:
    enabled: true
    # For full flexibility, we allow you to override any timescaledb-tune parameter below.
    # However, these parameters only take effect on newly scheduled pods and their settings are
    # only visibible inside those new pods.
    # Therefore you probably want to set explicit overrides in patroni.bootstrap.dcs.postgresql.parameters,
    # as those will take effect as soon as possible.
    # https://github.com/timescale/timescaledb-tune
    args: {}
      # max-conns: 120
      # cpus: 5
      # memory: 4GB

  # pgBouncer does connection pooling for PostgreSQL
  # https://www.pgbouncer.org/
  # enabling pgBouncer will run an extra container in every Pod, serving a pgBouncer
  # pass-through instance
  pgBouncer:
    # Solve the problem of too many connections.
    # Needs more work, disable for now, as it's not working
    # as expected.
    enabled: false
    port: 6432
    config:
    # DANGER: The below settings are considered to be safe to set, and we recommend
    # you do set these to appropriate values for you.
    # However, for flexibility, we do allow the override of any pg_bouncer setting
    # many of which are vital to the operation of this helm chart.
    # The values we do not suggest altering are set in the template
    # https://github.com/timescale/helm-charts/blob/main/charts/timescaledb-single/templates/configmap-pgbouncer.yaml#L35-L50
    # Only override these settings if you are confident of  what you are doing.
      server_reset_query: DISCARD ALL
      max_client_conn: 500
      default_pool_size: 20
      pool_mode: transaction
    pg_hba:
    - local     all postgres                   peer
    - host      all postgres,standby 0.0.0.0/0 reject
    - host      all postgres,standby ::0/0     reject
    - hostssl   all all              0.0.0.0/0 md5
    - hostssl   all all              ::0/0     md5
    - hostnossl all all              0.0.0.0/0 reject
    - hostnossl all all              ::0/0     reject
    # Secret should contain user/password pairs in the format expected by pgbouncer
    # https://www.pgbouncer.org/config.html#authentication-file-format
    # example:
    # userlist.txt: |
    #   "username" "hashedpassword"
    #   "username2" "hashedpassword2"
    userListSecretName:

  networkPolicy:
    enabled: false
    prometheusApp: prometheus
    # Below you can specify a whitelist of Ingress rules, for more information:
    # https://kubernetes.io/docs/concepts/services-networking/network-policies/#the-networkpolicy-resource
    ingress:
    # - from:
    #   - podSelector:
    #       matchLabels:
    #         app: foo
    #   ports:
    #   - protocol: TCP
    #       port: 11111

  # Prometheus exporter for PostgreSQL server metrics.
  # https://github.com/prometheus-community/postgres_exporter
  prometheus:
    enabled: true
    image:
      repository: quay.io/prometheuscommunity/postgres-exporter
      tag: v0.11.1
      pullPolicy: IfNotPresent
    # Extra custom environment variables for prometheus.
    # These should be an EnvVar, as this allows you to inject secrets into the environment
    # https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.16/#envvar-v1-core
    env:
    # - name: NOT_A_SECRET
    #   value: "test"
    # - name: MYAPPLICATION_STANDBY_PASSWORDS
    #   valueFrom:
    #     secretKeyRef:
    #       name: myapplication-passwords
    #       key: standby
    # Additional volumes for prometheus, e.g., to support additional queries.
    # These should be a Volume, as this allows you to inject any kind of Volume
    # https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.16/#volume-v1-core
    volumes:
    # - name: exporter-config
    #   configMap:
    #     name: exporter-prometheus
    #     items:
    #       - key: metrics_queries
    #         path: queries.yaml
    # Additional volume mounts, to be used in conjunction with the above variable.
    # https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.16/#volumemount-v1-core
    volumeMounts:
    # - name: exporter-config
    #   mountPath: /var/exporter

  podMonitor:
    # Specifies whether PodMonitor for Prometheus operator should be created
    enabled: true
    path: /metrics
    interval: 10s
  # For new deployments, we would advise Parallel here, however as that change breaks previous
  # deployments, it is set to OrderedReady here
  podManagementPolicy: OrderedReady

  rbac:
    # Specifies whether RBAC resources should be created
    create: true

  serviceAccount:
    # Specifies whether a ServiceAccount should be created
    create: true
    # The name of the ServiceAccount to use.
    # If not set and create is true, a name is generated using the fullname template
    name:
    # A map of annotations to be set on the ServiceAccount
    annotations: {}

  debug:
    # This setting is mainly for during development, debugging or troubleshooting.
    # This command will be executed *before* the main container starts. In the
    # example below, we can mimick a slow restore by sleeping for 5 minutes before starting
    execStartPre:  # sleep 300

promscale:
  enabled: true
  replicaCount: 3
  extraArgs:
    - "--metrics.high-availability=true"
  extraEnv:
    - name: "TOBS_TELEMETRY_INSTALLED_BY"
      value: "helm"
    - name: "TOBS_TELEMETRY_VERSION"
      value: "14.6.0"
    - name: "TOBS_TELEMETRY_TRACING_ENABLED"
      value: "true"
    - name: "TOBS_TELEMETRY_TIMESCALEDB_ENABLED"
      value: "true"
  #connectionSecretName: "tricorder-promscale-connection"
  connection:
    # Database connection settings. If `uri` is not
    # set then the specific user, pass, host, port and
    # sslMode properties are used.
    uri: ""
    # user used to connect to TimescaleDB
    user: "postgres"
    password: "tricorder"
    # in the same namespace
    host: "timescaledb"
    port: 5432
    sslMode: require
    # database name in which to store the metrics
    # must be created before start
    dbName: postgres
  resources:
    requests:
      cpu: 50m
      memory: 500Mi
    limits:
      cpu: "1"
      memory: 1Gi
  # promscale configuration options. Values presented in this section are defaults. For full list of settings
  # and their default values go to https://github.com/timescale/promscale/blob/master/docs/configuration.md
  # Note that configuration options set here can be overriden by extraEnv as well as extraArgs.
  # Arguments passed in extraArgs take precedence over any other option.
  config:
    startup.dataset.config: |
      metrics:
        compress_data: true
        default_retention_period: 7d
      traces:
        default_retention_period: 7d

kube-prometheus-stack:
  enabled: true
  alertmanager:
    enabled: false
  grafana:
    enabled: true
    # This must be same as starship/src/api-server/cmd/main.go's
    # grafana_password flag value.
    #
    # TODO(jian): Create a variable as grafana_password, and use that here,
    # and set api-server's grafana_password flag value explicitly.
    adminPassword: tricorder
    image:
      repository: public.ecr.aws/tricorder/grafana
      # Overrides the Grafana image tag whose default is the chart appVersion
      # TODO(yzhao): Change this to inherit the tag of starship
      tag: v0.0.9
      sha: ''
      pullPolicy: IfNotPresent
    resources:
      requests:
        cpu: 10m
        memory: 128Mi
      limits:
        cpu: "1"
        memory: 2Gi
    sidecar:
      datasources:
        enabled: true
        label: tricorder_datasource
        labelValue: "true"
        defaultDatasourceEnabled: false

      dashboards:
        multicluster:
          global:
            enabled: false
        enabled: true
        files:
          - dashboards/k8s-cluster.json
          - dashboards/k8s-hardware.json
          - dashboards/apm-dependencies.json
          - dashboards/apm-home.json
          - dashboards/apm-service-dependencies-downstream.json
          - dashboards/apm-service-dependencies-upstream.json
          - dashboards/apm-service-overview.json
          - dashboards/promscale.json
          - dashboards/postgres-overview.json
          - dashboards/postgres-details.json
          - dashboards/demo-ebpf-http.json
          - dashboards/metadata-process.json
    persistence:
      type: pvc
      enabled: true
      size: 1Gi
      accessModes:
        - ReadWriteOnce
    prometheus:
      datasource:
        enabled: true
        # By default url of data source is set to ts-prom connector instance
        # deployed with this chart. If a connector isn't used this should be
        # set to the prometheus-server.
        url: "http://{{ .Release.Name }}-promscale.{{ .Release.Namespace }}.svc:9201"
    timescale:
      datasource:
        enabled: true
        user: postgres
        # leaving password empty will cause helm to generate a random password
        pass: "tricorder"
        dbName: postgres
        sslMode: require
        # By default the url/host is set to the db instance deployed
        # with this chart
        host: "timescaledb.{{ .Release.Namespace }}.svc"
        port: 5432
    jaeger:
      datasource:
        enabled: true
      # Endpoint for integrating jaeger datasource in grafana. This should point to HTTP endpoint, not gRPC.
      tricorderTracesQueryEndPoint: "{{ .Release.Name }}-promscale.{{ .Release.Namespace }}.svc:9201"

    additionalDataSources:
      - name: timescale-tricorder
        uid: timescaledb_tricorder
        access: proxy
        editable: false
        type: postgres
        url: timescaledb:5432
        database: tricorder
        user: postgres
        jsonData:
          postgresVersion: 1400
          timescaledb: true
        secureJsonData:
          password: tricorder
        version: 1
    serviceMonitor:
      enabled: true
      labels:
        release: prometheus
      interval: ""
      tlsConfig: {}

  prometheus:
    enabled: true
    prometheusSpec:
      scrapeInterval: "1m"
      evaluationInterval: "1m"
      replicas: 1
      retention: 1h
      retentionSize: 128MB
      replicaExternalLabelName: "__replica__"
      # Promscale requires a cluster label to be present for high availability mode.
      prometheusExternalLabelName: "cluster"

      remoteWrite:
        - url: "http://{{ .Release.Name }}-promscale.{{ .Release.Namespace }}.svc:9201/write"
          remoteTimeout: 100s
          queueConfig:
            capacity: 100000
            maxSamplesPerSend: 10000
            batchSendDeadline: 30s
            minShards: 20
            maxShards: 20
            minBackoff: 100ms
            maxBackoff: 10s
      # Prometheus pod storage spec
      storageSpec:
        # Using PersistentVolumeClaim
        # disable mount sub path, use the root directory of pvc
        disableMountSubPath: true
        volumeClaimTemplate:
          spec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 5Gi
      resources:
        requests:
          cpu: 100m
          memory: 512Mi
        limits:
          cpu: "1"
          memory: 2048Mi
